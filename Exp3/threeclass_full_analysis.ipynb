{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0dfd945",
   "metadata": {},
   "source": [
    "# Three-Class Low-Rate DDoS Full Analysis (Fixed)\n",
    "This notebook:\n",
    "1. Splits data by label\n",
    "2. Cleans data\n",
    "3. Prepares BENIGN, Slowloris, Slowhttptest subsets\n",
    "4. Defines Test scenarios and models\n",
    "5. Evaluates each model (MLP, RandomForest, LogisticRegression, XGBoost)\n",
    "   - Prints class counts before/after augmentation\n",
    "   - Shows confusion matrix and classification report\n",
    "   - Computes average recall of attack classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ee604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os, glob\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac1045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_cvae(X, y, n_samples): return X, y\n",
    "def augment_gan(X, y, n_samples): return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5418f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob('CIC-IDS-2017/*.csv')\n",
    "os.makedirs('split_by_label', exist_ok=True)\n",
    "for f in csv_files:\n",
    "    df = pd.read_csv(f)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    for lbl, g in df.groupby('Label'):\n",
    "        safe = lbl.replace('/', '_').replace(' ', '_')\n",
    "        g.to_csv(f'split_by_label/{safe}.csv', index=False)\n",
    "print('Split by label done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6373c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)\n",
    "df_all.columns = df_all.columns.str.strip()\n",
    "df = df_all.drop_duplicates().dropna()\n",
    "print('Cleaned shape:', df.shape)\n",
    "display(df['Label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4323f69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "benign = df[df['Label']=='BENIGN']\n",
    "slowloris = df[df['Label']=='DoS slowloris']\n",
    "slowhttptest = df[df['Label']=='DoS Slowhttptest']\n",
    "print('Samples: BENIGN=', len(benign), 'Slowloris=', len(slowloris), 'Slowhttptest=', len(slowhttptest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08795d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_split(n_b, n_sl, n_sht):\n",
    "    rep = lambda n, arr: n > len(arr)\n",
    "    df_s = pd.concat([\n",
    "        benign.sample(n=n_b, random_state=42, replace=rep(n_b, benign)),\n",
    "        slowloris.sample(n=n_sl, random_state=42, replace=rep(n_sl, slowloris)),\n",
    "        slowhttptest.sample(n=n_sht, random_state=42, replace=rep(n_sht, slowhttptest))\n",
    "    ], ignore_index=True)\n",
    "    df_s = df_s.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    X = df_s.drop(columns=['Label'])\n",
    "    y = df_s['Label'].map({'BENIGN':0, 'DoS slowloris':1, 'DoS Slowhttptest':2})\n",
    "    Xs = StandardScaler().fit_transform(X)\n",
    "    return train_test_split(Xs, y, test_size=0.3, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = {\n",
    "    'Test1': {'benign':len(slowloris), 'slowloris':len(slowloris), 'slowhttptest':len(slowloris)},\n",
    "    'Test2': {'benign':len(benign), 'slowloris':len(slowloris), 'slowhttptest':len(slowhttptest)},\n",
    "    'Test3': {'benign':len(slowloris)//2, 'slowloris':len(slowloris)//2, 'slowhttptest':len(slowhttptest)//2},\n",
    "    'Test4': {'benign':len(slowloris)*2, 'slowloris':len(slowloris), 'slowhttptest':len(slowhttptest)}\n",
    "}\n",
    "methods = ['None', 'SMOTE', 'ADASYN', 'CVAE', 'GAN']\n",
    "models = {\n",
    "    'MLP': MLPClassifier(random_state=42, max_iter=500, early_stopping=True),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d945d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate MLP for three-class classification (fixed printing)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "for t, sz in tests.items():\n",
    "    X_tr, X_te, y_tr, y_te = sample_and_split(sz['benign'], sz['slowloris'], sz['slowhttptest'])\n",
    "    for m in methods:\n",
    "        cnt = np.bincount(y_tr, minlength=3)\n",
    "        print(f\"Test={t}, Aug={m} BEFORE counts: BENIGN={cnt[0]}, Slowloris={cnt[1]}, Slowhttptest={cnt[2]}\")\n",
    "        if m == 'SMOTE':\n",
    "            X_aug, y_aug = SMOTE(random_state=42).fit_resample(X_tr, y_tr)\n",
    "        elif m == 'ADASYN':\n",
    "            try:\n",
    "                X_aug, y_aug = ADASYN(random_state=42).fit_resample(X_tr, y_tr)\n",
    "            except ValueError:\n",
    "                X_aug, y_aug = X_tr, y_tr\n",
    "        elif m == 'CVAE':\n",
    "            X_aug, y_aug = augment_cvae(X_tr, y_tr, sz['benign'])\n",
    "        elif m == 'GAN':\n",
    "            X_aug, y_aug = augment_gan(X_tr, y_tr, sz['benign'])\n",
    "        else:\n",
    "            X_aug, y_aug = X_tr, y_tr\n",
    "        cnt2 = np.bincount(y_aug, minlength=3)\n",
    "        print(f\"Test={t}, Aug={m} AFTER counts: BENIGN={cnt2[0]}, Slowloris={cnt2[1]}, Slowhttptest={cnt2[2]}\")\n",
    "        clf = models['MLP']\n",
    "        clf.fit(X_aug, y_aug)\n",
    "        y_pred = clf.predict(X_te)\n",
    "        cm = confusion_matrix(y_te, y_pred)\n",
    "        print(\"Confusion Matrix:\\n\", cm)\n",
    "        print(\"Classification Report:\\n\", classification_report(y_te, y_pred, digits=4))\n",
    "        rec1 = recall_score(y_te, y_pred, labels=[1], average='macro')\n",
    "        rec2 = recall_score(y_te, y_pred, labels=[2], average='macro')\n",
    "        print(f\"Attack Recall avg: {(rec1 + rec2)/2:.4f}\\n\")\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a362d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate RandomForest for three-class classification\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "for t, sz in tests.items():\n",
    "    X_tr, X_te, y_tr, y_te = sample_and_split(sz['benign'], sz['slowloris'], sz['slowhttptest'])\n",
    "    for m in methods:\n",
    "        cnt = np.bincount(y_tr, minlength=3)\n",
    "        print(f\"Test={t}, Aug={m} BEFORE counts: BENIGN={cnt[0]}, Slowloris={cnt[1]}, Slowhttptest={cnt[2]}\")\n",
    "        if m == 'SMOTE':\n",
    "            X_aug, y_aug = SMOTE(random_state=42).fit_resample(X_tr, y_tr)\n",
    "        elif m == 'ADASYN':\n",
    "            try:\n",
    "                X_aug, y_aug = ADASYN(random_state=42).fit_resample(X_tr, y_tr)\n",
    "            except ValueError:\n",
    "                X_aug, y_aug = X_tr, y_tr\n",
    "        elif m == 'CVAE':\n",
    "            X_aug, y_aug = augment_cvae(X_tr, y_tr, sz['benign'])\n",
    "        elif m == 'GAN':\n",
    "            X_aug, y_aug = augment_gan(X_tr, y_tr, sz['benign'])\n",
    "        else:\n",
    "            X_aug, y_aug = X_tr, y_tr\n",
    "        cnt2 = np.bincount(y_aug, minlength=3)\n",
    "        print(f\"Test={t}, Aug={m} AFTER counts: BENIGN={cnt2[0]}, Slowloris={cnt2[1]}, Slowhttptest={cnt2[2]}\")\n",
    "        clf = models['RandomForest']\n",
    "        clf.fit(X_aug, y_aug)\n",
    "        y_pred = clf.predict(X_te)\n",
    "        cm = confusion_matrix(y_te, y_pred)\n",
    "        print(\"Confusion Matrix:\\n\", cm)\n",
    "        print(\"Classification Report:\\n\", classification_report(y_te, y_pred, digits=4))\n",
    "        rec1 = recall_score(y_te, y_pred, labels=[1], average='macro')\n",
    "        rec2 = recall_score(y_te, y_pred, labels=[2], average='macro')\n",
    "        print(f\"Attack Recall avg: {(rec1 + rec2)/2:.4f}\\n\")\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f0264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate LogisticRegression for three-class classification\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "for t, sz in tests.items():\n",
    "    X_tr, X_te, y_tr, y_te = sample_and_split(sz['benign'], sz['slowloris'], sz['slowhttptest'])\n",
    "    for m in methods:\n",
    "        cnt = np.bincount(y_tr, minlength=3)\n",
    "        print(f\"Test={t}, Aug={m} BEFORE counts: BENIGN={cnt[0]}, Slowloris={cnt[1]}, Slowhttptest={cnt[2]}\")\n",
    "        if m == 'SMOTE':\n",
    "            X_aug, y_aug = SMOTE(random_state=42).fit_resample(X_tr, y_tr)\n",
    "        elif m == 'ADASYN':\n",
    "            try:\n",
    "                X_aug, y_aug = ADASYN(random_state=42).fit_resample(X_tr, y_tr)\n",
    "            except ValueError:\n",
    "                X_aug, y_aug = X_tr, y_tr\n",
    "        elif m == 'CVAE':\n",
    "            X_aug, y_aug = augment_cvae(X_tr, y_tr, sz['benign'])\n",
    "        elif m == 'GAN':\n",
    "            X_aug, y_aug = augment_gan(X_tr, y_tr, sz['benign'])\n",
    "        else:\n",
    "            X_aug, y_aug = X_tr, y_tr\n",
    "        cnt2 = np.bincount(y_aug, minlength=3)\n",
    "        print(f\"Test={t}, Aug={m} AFTER counts: BENIGN={cnt2[0]}, Slowloris={cnt2[1]}, Slowhttptest={cnt2[2]}\")\n",
    "        clf = models['LogisticRegression']\n",
    "        clf.fit(X_aug, y_aug)\n",
    "        y_pred = clf.predict(X_te)\n",
    "        cm = confusion_matrix(y_te, y_pred)\n",
    "        print(\"Confusion Matrix:\\n\", cm)\n",
    "        print(\"Classification Report:\\n\", classification_report(y_te, y_pred, digits=4))\n",
    "        rec1 = recall_score(y_te, y_pred, labels=[1], average='macro')\n",
    "        rec2 = recall_score(y_te, y_pred, labels=[2], average='macro')\n",
    "        print(f\"Attack Recall avg: {(rec1 + rec2)/2:.4f}\\n\")\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f470de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate XGBoost for three-class classification\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "for t, sz in tests.items():\n",
    "    X_tr, X_te, y_tr, y_te = sample_and_split(sz['benign'], sz['slowloris'], sz['slowhttptest'])\n",
    "    for m in methods:\n",
    "        cnt = np.bincount(y_tr, minlength=3)\n",
    "        print(f\"Test={t}, Aug={m} BEFORE counts: BENIGN={cnt[0]}, Slowloris={cnt[1]}, Slowhttptest={cnt[2]}\")\n",
    "        if m == 'SMOTE':\n",
    "            X_aug, y_aug = SMOTE(random_state=42).fit_resample(X_tr, y_tr)\n",
    "        elif m == 'ADASYN':\n",
    "            try:\n",
    "                X_aug, y_aug = ADASYN(random_state=42).fit_resample(X_tr, y_tr)\n",
    "            except ValueError:\n",
    "                X_aug, y_aug = X_tr, y_tr\n",
    "        elif m == 'CVAE':\n",
    "            X_aug, y_aug = augment_cvae(X_tr, y_tr, sz['benign'])\n",
    "        elif m == 'GAN':\n",
    "            X_aug, y_aug = augment_gan(X_tr, y_tr, sz['benign'])\n",
    "        else:\n",
    "            X_aug, y_aug = X_tr, y_tr\n",
    "        cnt2 = np.bincount(y_aug, minlength=3)\n",
    "        print(f\"Test={t}, Aug={m} AFTER counts: BENIGN={cnt2[0]}, Slowloris={cnt2[1]}, Slowhttptest={cnt2[2]}\")\n",
    "        clf = models['XGBoost']\n",
    "        clf.fit(X_aug, y_aug)\n",
    "        y_pred = clf.predict(X_te)\n",
    "        cm = confusion_matrix(y_te, y_pred)\n",
    "        print(\"Confusion Matrix:\\n\", cm)\n",
    "        print(\"Classification Report:\\n\", classification_report(y_te, y_pred, digits=4))\n",
    "        rec1 = recall_score(y_te, y_pred, labels=[1], average='macro')\n",
    "        rec2 = recall_score(y_te, y_pred, labels=[2], average='macro')\n",
    "        print(f\"Attack Recall avg: {(rec1 + rec2)/2:.4f}\\n\")\n",
    "    print('-'*60)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
